The idea behind entmesh: To allow entropy to move from where it's abundant to
where it's needed within a network of computers.

Terms:
* Tank: A node where entropy is stored. Examples include the kernel entropy
  pool, as well as userland buffers.
* Source: A node where entropy is generated. Examples include the kernel's own
  attempts at generating entropy, as well as hardware TRNGs, haveged, etc.
  This is abstracted as a tank which is always full.
* Peer: A node connected to another node.

Peer relationships:
* When two nodes are connected to each other, they have a relationship as
  peers.
* Each node in a peer relationship may choose whether or not it will send or
  receive data from its peer. This has a logical basis in that a hardware TRNG
  cannot receive data, and it has a security basis in that we may not trust
  the quality of entropy from a peer, even though we may wish to provide it
  with entropy.
* Peers may notify each other about their current entropy level. Such
  notifications carry implicit flow control requests; if a node notifies its
  peer that it's starving for entropy, it's implicitly requesting that its
  peer send it entropy.

Signaling events:
* Entropy Transfer Request: When a node requests that its peer send it
  entropy.
* State Notificaton: When a node informs its peer of its current state.

Tank levels, notifications and responses:

+---------------------+----------------------------+
|        STATES       |                            |
+----------+----------+ Implicit Transfer Requests |
|  Node A  |  Node B  |                            |
+----------+----------+----------------------------+
|   GOOD   |   GOOD   | None                       |
+----------+----------+----------------------------+
|   GOOD   |    OK    | None                       |
+----------+----------+----------------------------+
|   GOOD   |    LOW   | B requests entropy from A. |
+----------+----------+----------------------------+
|   GOOD   | CRITICAL | B requests entropy from A. |
+----------+----------+----------------------------+
|    OK    |   GOOD   | None                       |
+----------+----------+----------------------------+
|    OK    |    LOW   | B requests entropy from A. |
+----------+----------+----------------------------+
|    OK    | CRITICAL | B requests entropy from A. |
+----------+----------+----------------------------+
|    LOW   |    LOW   | None                       |
+----------+----------+----------------------------+
|    LOW   | CRITICAL | None                       |
+----------+----------+----------------------------+
| CRITICAL | CRITICAL | None                       |
+----------+----------+----------------------------+

What exactly corresponds to GOOD, OK, LOW or CRITICAL depends on the tank
abstraction implementation.

It is an error for a node to transmit the same state twice; if it is already
known to be in the GOOD state, and it announces again that it is in the GOOD
state, it is in error, and the peering should be terminated.

A node which receives an entropy transfer request is not required to send
entropy in response.

A node which receives a state update from its peer may discover that its peer
is at a lower state than itself. It MUST treat this as an implicit entropy
transfer request. If its peer is two or more steps lower, it SHOULD service
the request.


Offers, acceptence, sending and ceasing:
Example topologies:

K = Kernel entropy pool, abstracted as a tank.
M = Memory FIFO entropy buffer, abstracted as a tank.

Single-host, no external entropy source:
K<->M
* K Trusts M
* M Trusts K

In this example, some internal abstraction driver describes the kernel entropy
pool as a tank, monitors its level, handles state announcements and
pushing/pulling of data. Since the kernel entropy pool only stores a very,
very small amount of entropy (512 bytes), having a separate M tank can be
beneficial; it allows us to save off any excess entropy generated that
wouldn't otherwise have fit in K. When K runs low, entropy is moved from M
back into K.

Two hosts, equally trusted:

K1 <-> M1 <-> M2 <-> K2

* K1 and M1 are on the same host
* K1 and M1 trust each other.
* K2 and M2 are on the same host
* K2 and M2 trust each other.
* M1 and M2 trust each other.

In this example, the Linux kernel for host 1 will attempt to fill K1, and the kernel for
host 2 will likewise fill K2. K1 and M2 will attempt to keep each other
filled, K2 and M2 will attempt to keep each other filled, and M1 and M2 will
attempt to keep each other filled.

So, if K2 runs dry, draining M2, then M1 will feed into M2, which will feed
into K2. If M1 runs dry, K1 will attempt to fill it.

Likewise, if K1 runs dry, draining M1, then M2 will feed into M1, and K2 will
feed into M2.

In this way, entropy will flow from where it's available to where it's needed.

Two hosts, unequal trust:
Let's say that in the situation above, host 1 does not trust the quality of
entropy from host 2, but does want to keep host 2 supplied with entropy.
(Perhaps host 1 has an HRNG tied into K1)

K1 <-> M1 -> M2 <-> K2

Here, if M1 runs LOW, it will announce its LOW state to K1, which will fill
it. It will *not* announce its LOW state to M2.

Client/Server entropy cluster:

K1 <-> M1 <--v
K2 <-> M2 <->M3-,
                +------->M4<->K4
                +------->M5<->K5
                +------->M6<->K6
                +------->M7<->K7
                 \------>M8<->K8

Here, you have two hosts, 1 and 2, sharing trust with buffer M3. M4-M8 aren't
trusted by anyone but their hosts' kernels, and it's M3's job to keep them
supplied with entropy.

(This is how I see entmesh being useful in VM cluster environments.)
